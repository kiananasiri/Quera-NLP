{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ced3d12",
   "metadata": {
    "id": "4ced3d12"
   },
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "کاوش در کتابخانه زندگی\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7958a",
   "metadata": {
    "id": "36e7958a"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "</div>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این تمرین قصد داریم با آنجه که در این فصل آموختیم کارکنیم. یک فایل متنی <code>Library_of_Life.txt</code> در اختیار شما قرار گرفته شده است که می‌بایست با استفاده از هرسه روش توکن‌سازی (توکن‌سازی براساس کلمه، توکن‌سازی براساس کاراکتر و توکن‌سازی براساس زیرکلمه) به تحلیل فرکانس (تعداد تکرارهای کلمات) در این متن بپردازید و در انتها در هر روش ۱۰ موردی که بیشترین فرکانس را داشتند را مشخص کنیم.\n",
    "    </font>\n",
    "    </p>\n",
    "    \n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    درپایان تمرین با مفاهیم زیر به صورت عملی کار خواهیم کرد:\n",
    "    </font>\n",
    "    </p>\n",
    "    \n",
    "<div dir=\"rtl\">    \n",
    "    \n",
    "+ **بازکردن و خواندن فایل**\n",
    "+ **استفاده از ابزار توکن‌سازی**\n",
    "+ **یافتن فراکانس کلمات**\n",
    "+ **مصور سازی**\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6cf92",
   "metadata": {
    "id": "25f6cf92"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای اینکار می‌بایست ابتدا فایل متنی را باز کرده و محتویات آن را بخوانیم\n",
    "    </font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadb736a",
   "metadata": {
    "id": "cadb736a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once upon a time, in a quiet little town nestled between rolling green hills, there was an old library known as The Library of Life. It was said to hold the secrets of learning, love, and the mysteries of existence itself. People came from far and wide to explore its dusty shelves, but no one truly understood its purpose—until a young woman named Elara arrived.\\n', '\\n', 'Elara was a curious soul, always searching for meaning. She spent her days reading, learning about the world, and questioning everything. One day, while wandering the aisles of the library, she found an ancient book titled The Three Lessons.\\n', '\\n', 'When she opened it, the first page read:\\n', '“To learn is to live. To love is to grow. To understand is to become.”\\n', '\\n', 'Intrigued, Elara turned the page. It instructed her to find a stranger in the library and share her favorite story with them. Nervously, she approached a young man sitting near the window, his nose buried in a book. His name was Arin.\\n', '\\n', 'They began talking, and soon, they were laughing, sharing stories of their lives and dreams. Over time, their conversations turned into friendship, and friendship blossomed into love. Together, they returned to The Three Lessons.\\n', '\\n', 'The second page read:\\n', '“Love teaches us the lessons that books cannot.”\\n', '\\n', 'With Arin by her side, Elara realized that learning wasn’t just about facts and knowledge; it was about connection, empathy, and growth. They traveled together, exploring the world and its wonders, learning from every person they met.\\n', '\\n', 'Finally, one rainy evening, they turned to the last page of the book. It said:\\n', '“The greatest lesson of life is to embrace every moment—both the joy and the pain—because every moment is a story worth telling.”\\n', '\\n', 'Elara closed the book, her heart full of gratitude. She understood now: life was the ultimate library, and every experience was a chapter in its endless story.\\n', '\\n', 'From that day forward, Elara and Arin continued their journey, not just as learners, but as storytellers, writing their own book in the library of life.\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode from the specified path\n",
    "with open(\"../data/The_Library_of_Life.txt\", 'r', encoding=\"utf8\") as file:\n",
    "    \n",
    "    # read file\n",
    "    text = file.readlines()\n",
    "    \n",
    "\n",
    "# show text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816566d6",
   "metadata": {},
   "source": [
    "<details class='green'>\n",
    "    <summary>\n",
    "        <p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <font face=\"vazir\" size=3>\n",
    "            نصب کتابخانه‌ها\n",
    "            </font>\n",
    "        </p>\n",
    "    </summary>\n",
    "    \n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "        اگر کتابخانه‌های زیر را در سیستم خود ندارید، می‌توانید با اجرای دستورات زیر آن‌ها در سیستم خود نصب کنید.\n",
    "    </font>\n",
    "</p>\n",
    "\n",
    "```python\n",
    "!pip install spacy\n",
    "!pip install transformers\n",
    "!pip install numpy==1.16\n",
    "!pip install pandas\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87d5df",
   "metadata": {
    "id": "5e87d5df"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال که محتویات متن را در برنامه خود قرار دادیم نوبت به آن است که با فراخوانی کتابخانه مورد نیاز به پیش‌پردازش آن بپردازیم که در این بخش به شما، کتابخانه <code>spaCy</code> پیشنهاد می‌شود اما شما می‌توانید با استفاده از کتابخانه‌های دیگری که خود می‌دانید اینکار را انجام دهید.\n",
    "    </font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e4915c",
   "metadata": {
    "id": "10e4915c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import transformers as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24a1f4",
   "metadata": {
    "id": "bf24a1f4"
   },
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "توکن‌سازی کلمه‌ای\n",
    "</font>\n",
    "</h2>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    با توجه به زبان (انگلیسی)، کوتاهی متن داستان و قابلیت‌های توکن‌سازی براساس کلمه برای این‌نوع زبان‌ها یکی از موارد مناسب برای این تمرین می‌تواند مناسب باشد. \n",
    "    پس در این بخش می‌بایست به توکن‌سازی داستان براساس کلمه بپردازیم.\n",
    "    برای اینکار یکی از ابزار مهمی که در اختیار داریم کتابخانه <code>spaCy</code> می‌باشد \n",
    "    </font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d5639",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "        برای اینکار ابتدا باید مدل مورد نظر از کتابخانه <code>spaCy</code> را با توجه به متن و نوع کاربرد خود دانلود کنیم و سپس آن را بارگزاری کنیم.<br>\n",
    "        برای این تمرین مدل <code>en_core_web_sm</code> می‌تواند مناسب باشد.\n",
    "    </font>\n",
    "</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fe2bb8",
   "metadata": {
    "id": "c3fe2bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m316.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "# download the appropriate model\n",
    "spacy.cli.download('en_core_web_sm')\n",
    "\n",
    "# load the model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b0ef1",
   "metadata": {
    "id": "605b0ef1"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پس از آنکه مدل مورد نظر خود را دانلود و در برنامه بارگذاری کردیم نوبت به توکن‌سازی کلمه‌ای متن میرسد.\n",
    "    نتیجه پردازش داستان را در متغیری به‌نام <code>doc_preprocessing</code> ذخیره می‌کنیم.\n",
    "</font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cb4084",
   "metadata": {
    "id": "06cb4084"
   },
   "outputs": [],
   "source": [
    "# do preprocessing with spaCy (nlp)\n",
    "doc_preprocessing = nlp(''.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c01a0d",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "        پس از پیش پردازش متن توسط خط لوله <code>spaCy</code> یکی از نتایجی که این <code>piplien</code> در اختیار ما قرار می‌دهد توکن‌های کلمه ایست. این توکن‌ها را استخراج کرده و در یک متغیر به نام <code>word_tokenize</code> دخیره کنید. \n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2c18daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word token separation\n",
    "word_tokenize = [ token.text for token in doc_preprocessing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca205b",
   "metadata": {
    "id": "74ca205b"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در توکن‌سازی کلمه‌ای، یکی از عوامل موثر در بدست آوردن اطلاعات با ارزش حذف نویز و کلمات توقف است که با استفاده از کتابخانه‌های <code>nltk</code> و <code>string</code> قابل انجام است.<br>\n",
    "    وجود این عوامل باعث کاهش دقت و افزایش حجم داده‌ها در سیستم‌ها می‌شود.\n",
    "    </font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6037b12",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "        در مرحله اول ابتدا با استفاده از کتابخانه <code>nltk</code> و ماژول <code>corpus</code> ، کلمات توقف را بارگزاری کرده و توکن‌های غیر توقف را جداسازی می‌کنیم.<br>\n",
    "        حاصل این فرایند را در متغیری بنام <code>word_token</code> ذخیره می‌کنیم.\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe9584c",
   "metadata": {
    "id": "dfe9584c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kiananasiri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['upon', 'time', ',', 'quiet', 'little']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the stopwords\n",
    "\n",
    "# Loading stop words tool\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download the stopwords set \n",
    "nltk.download('stopwords')\n",
    "\n",
    "# save the stopwords tokens in english in a variable\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Separating non-stop tokens\n",
    "word_token = [w for w in word_tokenize if not w.lower() in stop_words]\n",
    "word_token[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910c53f",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "            در گام دوم در حذف نویز، باید به حذف اعلائم نگارشی مانند <code>؟</code> ، <code>.</code> و ... بپردازیم که برای اینکار با استفاده از کتابخانه <code>string</code> و ماژول <code>punctuation</code> به انجام اینکار می‌پردازیم.\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc69ee69",
   "metadata": {
    "id": "dc69ee69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of word tokenize data frame: 212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['upon', 'time', 'quiet', 'little', 'town']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete punctuation\n",
    "\n",
    "# load the string module for import punctuation set ( you can do this operation with nltk)\n",
    "import string\n",
    "\n",
    "# save the punctuation in variable\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Separating non-puncuation tokens\n",
    "word_token = [w for w in word_token if not w in punctuations]\n",
    "\n",
    "# Getting the length of tokes\n",
    "lenth_of_word_tokenize = len(word_token)\n",
    "\n",
    "print(f'lenth of word tokenize data frame: {lenth_of_word_tokenize}')\n",
    "word_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "542e899a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unique'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9963ebb",
   "metadata": {
    "id": "f9963ebb"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پس از نویز زدایی توکن‌ها کافی است که فرکانس (تعداد تکرار) توکن‌ها را حساب کرده و در یک دیتافریم به‌نام <code>word_tokenize_frequency_df</code> ذخیره کنیم.\n",
    "    </font>\n",
    "    </p>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "دیتا فریم می‌بایست به مشابه شکل زیر باشد(مقادیر دیتافریم شما با شکل متفاوت است):\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| | token | frequncy|\n",
    "|---|----|-----|\n",
    "| 0 | upon | 5 |\n",
    "| 1 | home | 12 |\n",
    "| 2 | book | 2 |\n",
    "| ... | ... | ... |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b643630",
   "metadata": {
    "id": "4b643630"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quiet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>town</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  frequency\n",
       "0    upon          1\n",
       "1    time          2\n",
       "2   quiet          1\n",
       "3  little          1\n",
       "4    town          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_token_freq = Counter(word_token)\n",
    "word_tokenize_frequency_df = pd.DataFrame(word_token_freq.items(), columns=['token', 'frequency'])\n",
    "word_tokenize_frequency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8aa662",
   "metadata": {
    "id": "dd8aa662"
   },
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال کافیسیت که 10 توکنی که بیشترین فرکانس را دارا هستند را همراه با تعداد تکرار آن‌ها در متن را  در متغیری به نام <code>top_10_word_token_df</code> ذخیره کنیم.\n",
    "    </font>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99727a50",
   "metadata": {
    "id": "99727a50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Elara</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>library</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>book</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>learning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>page</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>every</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>—</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  frequency\n",
       "38       \\n\\n         10\n",
       "36      Elara          6\n",
       "10    library          5\n",
       "56       book          5\n",
       "17   learning          4\n",
       "62       page          4\n",
       "121     every          4\n",
       "18       love          3\n",
       "32          —          3\n",
       "64         \\n          3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top_10_word_token_df = word_tokenize_frequency_df.nlargest(10 , 'frequency')\n",
    "top_10_word_token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d1128",
   "metadata": {
    "id": "5d6d1128"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "توکن‌سازی کاراکتری\n",
    "</font>\n",
    "</h2>\n",
    "</div>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال نوبت به توکن‌سازی کاراکتری متون می‌باشد در این بخش می‌بایست که داده‌های متنی خود را به حالت کاراکتری ذخیره کرده و احتیاجی به نویز گیری داده‌ها نیست چرا که تمام حروف و توالی این حروف و کاراکترها برای ما ارزشمند است پس نیازی به حذف علائم نگارشی در این مبحث نیست\n",
    "    .\n",
    "    </font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    <font face=\"vazir\" size=3>\n",
    "        همینطور که در درسنامه‌های این فصل مشاهده کردیم، این نوع توکن‌سازی برای زبان‌هایی مناسب است که ساختار پیچیده‌تری بین حروف کلمات آن وجود دارد و یافتن الگوی بین این کلمات برای ما ارزش بیشتری دارد.\n",
    "    </font>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    فراکانس تمام کاراکترها را حساب کرده و در یک دیتافریم به نام <code>char_tokenize_frequency_df</code> ذخیره کنید.\n",
    "    10 کاراکتری که بیشترین میزان فراکانس را در کاراکتر‌ها را داراهستند در یک متغیر به نام <code>top_10_char_df</code> ذخیره کنید.\n",
    "    </font>\n",
    "    </p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "دیتا فریم می‌بایست به مشابه شکل زیر باشد: (مقادیر دیتافریم شما با شکل متفاوت است)\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| | token | frequncy|\n",
    "|---|----|-----|\n",
    "| 0 | A | 5 |\n",
    "| 1 | o | 12 |\n",
    "| 2 | z | 2 |\n",
    "| ... | ... | ... |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44a8a867",
   "metadata": {
    "id": "44a8a867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    }
   ],
   "source": [
    "# char tokenize\n",
    "char_tokenize = list(''.join(text))\n",
    "\n",
    "# Getting the length of char tokenize set\n",
    "length_of_char_tokenize = len(char_tokenize)\n",
    "\n",
    "print(length_of_char_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65af7b19",
   "metadata": {
    "id": "65af7b19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  frequency\n",
       "0     O          3\n",
       "1     n        128\n",
       "2     c         23\n",
       "3     e        211\n",
       "4              329"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the frequency of tokens and save in the \"char_tokenize_frequency_df\"\n",
    "from collections import Counter\n",
    "char_tokenize_frequency_df = pd.DataFrame( Counter(char_tokenize).items() , columns=['token' , 'frequency'] )\n",
    "char_tokenize_frequency_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75735f55",
   "metadata": {
    "id": "75735f55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>r</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  frequency\n",
       "4               329\n",
       "3      e        211\n",
       "9      t        136\n",
       "1      n        128\n",
       "8      a        122\n",
       "19     r        120\n",
       "7      o        117\n",
       "10     i        104\n",
       "16     s        103\n",
       "21     h         75"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_chars_df = char_tokenize_frequency_df.nlargest(10, 'frequency')\n",
    "top_10_chars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b0481",
   "metadata": {
    "id": "044b0481"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "    <h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "توکن‌سازی زیرکلمه‌ای\n",
    "</font>\n",
    "</h2>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "در این بخش به توکن‌سازی داستان براساس زیرکلمه‌ها می‌پردازیم و در این مرحله فراکانس تمام توکن‌ها را گرفته در یک دیتافریم به نام\n",
    "    <code>subword_tokenize_frequency_df</code> ذخیره کنید.\n",
    "    </font>\n",
    "    </p>\n",
    "    </div>\n",
    "    \n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    فراکانس تمام توکن‌ها را حساب کرده و در یک دیتافریم به نام <code>char_tokenize_frequency_df</code> ذخیره کنید.\n",
    "    10 کاراکتری که بیشترین میزان فراکانس را در توکن‌ها را داراهستند در یک متغیر به نام <code>top_10_subword_df</code> ذخیره کنید.\n",
    "    </font>\n",
    "    </p>\n",
    "\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "دیتا فریم می‌بایست به مشابه شکل زیر باشد: (مقادیر دیتافریم شما با شکل متفاوت است)\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| | token | frequncy|\n",
    "|---|----|-----|\n",
    "| 0 | home | 5 |\n",
    "| 1 | ##ara | 12 |\n",
    "| 2 | they | 2 |\n",
    "| ... | ... | ... |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a957b-2d64-433c-8e1b-7a720f2d8bfc",
   "metadata": {},
   "source": [
    "\n",
    "<details class=\"red\">\n",
    "    <summary>\n",
    "        <div dir=\"rtl\">\n",
    "            <strong>\n",
    "                نصب کتابخانه transformers\n",
    "            </strong>\n",
    "        </div>\n",
    "    </summary>\n",
    "    <p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <font face=\"vazir\" size=3>\n",
    "            اگر بروی سیستم شما کتابخانه <code>transformers</code> نصب نیست از طریق دستور العمل زیر می‌توانید اقدام کنید.\n",
    "        </font>\n",
    "    </p>\n",
    "\n",
    "```python\n",
    "\n",
    "!pip install transformers\n",
    "\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08bb2d23",
   "metadata": {
    "id": "08bb2d23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['once', 'upon', 'a', 'time', ',']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing auto tokenizer for subword tokenizer from transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the tokenizer  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# tokenization\n",
    "subword_tokens = tokenizer.tokenize(''.join(text))  \n",
    "subword_tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b4a0b",
   "metadata": {
    "id": "cd7b4a0b"
   },
   "source": [
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در توکن‌سازی زیرکلمه‌ای (Subword Tokenization)، نیازی به حذف نویز یا علائم نگارشی به‌طور کلی وجود ندارد، زیرا این روش طراحی شده است که حتی با وجود نویز و علائم نگارشی نیز به‌خوبی عمل کند\n",
    ".</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55ce172d",
   "metadata": {
    "id": "55ce172d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>once</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quiet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>little</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>town</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nestled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>between</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rolling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hills</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>there</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>was</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>an</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>library</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  frequency\n",
       "0      once          1\n",
       "1      upon          1\n",
       "2         a          9\n",
       "3      time          2\n",
       "4         ,         33\n",
       "5        in          5\n",
       "6     quiet          1\n",
       "7    little          1\n",
       "8      town          1\n",
       "9   nestled          1\n",
       "10  between          1\n",
       "11  rolling          1\n",
       "12    green          1\n",
       "13    hills          1\n",
       "14    there          1\n",
       "15      was          7\n",
       "16       an          2\n",
       "17      old          1\n",
       "18  library          6\n",
       "19    known          1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword_tokenize_frequency_df = pd.DataFrame( Counter(subword_tokens).items() , columns=['token' , 'frequency'] )\n",
    "subword_tokenize_frequency_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "631d9da7",
   "metadata": {
    "id": "631d9da7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>and</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>to</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>of</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>was</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>library</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>el</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  frequency\n",
       "4         ,         33\n",
       "24        .         24\n",
       "21      the         23\n",
       "32      and         13\n",
       "27       to         12\n",
       "2         a          9\n",
       "22       of          9\n",
       "15      was          7\n",
       "18  library          6\n",
       "56       el          6"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_subword_df = subword_tokenize_frequency_df.nlargest(10 , 'frequency')\n",
    "top_10_subword_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539799d-dc2f-4284-8c2c-339361912b62",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">  \n",
    "    <p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <font face=\"vazir\" size=3>\n",
    "            در این قسمت، هر سه دیتافریمی که از 10 توکن با بیشترین فرکانس را ایجاد کردیم تبدیل به یک دیتافریم واحد می‌کنیم.\n",
    "        </font>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "VAV-AVbNKjv_",
   "metadata": {
    "id": "VAV-AVbNKjv_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elara</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>library</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>page</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>every</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>—</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>o</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>h</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>,</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>and</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>to</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>of</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>was</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>library</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>el</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  frequency\n",
       "0       \\n\\n         10\n",
       "1      Elara          6\n",
       "2    library          5\n",
       "3       book          5\n",
       "4   learning          4\n",
       "5       page          4\n",
       "6      every          4\n",
       "7       love          3\n",
       "8          —          3\n",
       "9         \\n          3\n",
       "10                  329\n",
       "11         e        211\n",
       "12         t        136\n",
       "13         n        128\n",
       "14         a        122\n",
       "15         r        120\n",
       "16         o        117\n",
       "17         i        104\n",
       "18         s        103\n",
       "19         h         75\n",
       "20         ,         33\n",
       "21         .         24\n",
       "22       the         23\n",
       "23       and         13\n",
       "24        to         12\n",
       "25         a          9\n",
       "26        of          9\n",
       "27       was          7\n",
       "28   library          6\n",
       "29        el          6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of dataframes\n",
    "frames = [top_10_word_token_df, top_10_chars_df, top_10_subword_df]\n",
    "\n",
    "# merging the dataframes\n",
    "submission = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# save the result dataframe as 'submission.csv' file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ea7c8",
   "metadata": {
    "id": "5c2ea7c8"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "</div>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49664557",
   "metadata": {
    "id": "49664557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['submission.csv', 'library_of_life_analysis.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = [ 'submission.csv', 'library_of_life_analysis.ipynb']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
